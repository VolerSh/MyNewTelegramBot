# Документация проекта MyNewTelegramBot

## 1. Концепция проекта

Этот проект представляет собой автоматизированную систему для мониторинга цен на товары (в частности, ноутбуки) на платформе Яндекс.Маркет. Система управляется через Telegram-бота и использует фреймворк Scrapy для эффективного сбора данных.

**Ключевые функции:**
- **Асинхронный запуск:** Управляется через `run_bot.py`, который обеспечивает стабильную работу.
- **Взаимодействие через Telegram:** Пользователи могут запускать задачи и получать уведомления через команды в Telegram.
- **Мощный парсинг:** Использует Scrapy для быстрого и надежного сбора данных с веб-сайтов.
- **Обработка данных:** Включает модуль для декомпозиции названий товаров и извлечения технических характеристик.
- **Хранение данных:** Результаты сохраняются в базу данных SQLite для последующего анализа и в отчеты (CSV, HTML).

---

## 2. Структура и описание файлов

### 2.1. Корневая директория

- **`run_bot.py`**: **Главная точка входа.** Этот скрипт запускает и управляет Telegram-ботом как дочерним процессом, обеспечивая стабильность и правильную работу импортов внутри проекта.
- **`requirements.txt`**: Список всех Python-библиотек, необходимых для работы проекта. Устанавливается командой `pip install -r requirements.txt`.
- **`scrapy.cfg`**: Стандартный конфигурационный файл Scrapy. Указывает, где находятся настройки проекта (`app.scraping.settings`).
- **`.env`**: Файл для хранения секретных данных (токенов, ключей API). **Никогда не должен попадать в систему контроля версий.**
- **`.env.example`**: Пример файла `.env`, который показывает, какие переменные окружения необходимо определить.
- **`marketplace_deals.db`**: Файл базы данных SQLite. Создается автоматически при первом сохранении данных.
- **`bot.log`**: Файл логов. Сюда записываются все события, ошибки и информационные сообщения от работающего приложения.
- **`*.csv`, `*.html`, `cache_*.json`**: Временные файлы и отчеты, генерируемые в процессе работы.

### 2.2. Директория `app` (основной код)

Пакет `app` содержит всю основную бизнес-логику проекта.

- **`app/config.py`**: Загружает переменные из `.env` и предоставляет их для использования в других частях приложения.
- **`app/logging_config.py`**: Настраивает систему логирования, определяя формат вывода и направления (в файл `bot.log` и в консоль).
- **`app/main.py`**: Устаревшая точка входа. Сохранена для истории, но не используется для запуска.

#### `app/telegram_bot/` — Модуль Telegram-бота

- **`bot.py`**: Отвечает за инициализацию экземпляра бота (`telebot.TeleBot`) и запуск процесса поллинга (опроса серверов Telegram на наличие новых сообщений).
- **`handlers.py`**: Содержит всю логику обработки команд и сообщений от пользователя. Реагирует на команды `/start`, `/search` и любые другие текстовые сообщения. Именно отсюда инициируется запуск парсинга.

#### `app/scraping/` — Модуль парсинга (Scrapy)

- **`spiders/yandex_market.py`**: "Сердце" парсера. Класс `YandexMarketSpider`, который знает, как перемещаться по страницам Яндекс.Маркета, находить нужные товары и извлекать из HTML-кода их название, цену и ссылку.
- **`settings.py`**: Файл настроек Scrapy. Здесь можно задать `USER_AGENT`, задержки между запросами (`DOWNLOAD_DELAY`), а также определить конвейеры (`ITEM_PIPELINES`) для пошаговой обработки данных.
- **`decomposer.py`**: Содержит класс `LaptopDecomposer`, который берет "сырое" название товара (например, "Ноутбук Lenovo ThinkBook 16 G6 16”/Ryzen 5/16GB/SSD 512GB") и "разбирает" его на составные части, извлекая технические характеристики с помощью регулярных выражений.
- **`utils.py`**: Вспомогательные функции. Главная из них — `run_spider`, которая программно запускает процесс Scrapy и возвращает собранные данные.

#### `app/database/` — Модуль базы данных

- **`database.py`**: Управляет подключением к базе данных SQLite через SQLAlchemy. Предоставляет сессии для выполнения запросов.
- **`models.py`**: Описывает структуру таблиц в базе данных. Класс `Product` определяет, какие колонки будут в таблице товаров (id, name, price, url и т.д.).

#### `app/analysis/` — Модуль анализа данных

- **`analyzer.py`**: Содержит логику для анализа уже собранных и сохраненных данных. Например, здесь могут быть функции для поиска товаров с лучшим соотношением цена/качество или для отслеживания динамики цен.

### 2.3. Прочие директории

- **`docs/`**: Директория с документацией проекта (этот файл и HTML-схемы).
- **`project_structure/`**: Старая директория с документацией. Будет удалена.
- **`.kilocode/`**: Правила и конфигурация для AI-ассистента.
- **`scripts/`**, **`tests/`**: Зарезервированные, но пока пустые директории для вспомогательных скриптов и автоматических тестов.